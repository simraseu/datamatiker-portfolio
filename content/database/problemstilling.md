---
title: "Problemstilling"
date: 2025-01-15
draft: false
weight: 1
---

## Fra tre chatbots til √©n kritisk beslutning

Vi skulle bygge en Blazor-webapp med tre AI-chatbots: √©n for g√¶ster, √©n for brugere og √©n for administratoren. Men jeg stod overfor et fundamentalt sp√∏rgsm√•l: **Hvilken database?**

Min f√∏rste tanke var simpel: "MongoDB til JSON, PostgreSQL til relationel data, Pinecone til vector search." Tre systemer. Tre databaser. Tre synkroniseringsproblemer.

Men moderne LLM'er komplicerer billedet. GPT-4 er stateless ‚Äì den husker intet mellem API-kald. Derfor skal **vi** gemme al kontekst. Hver besked. Hver samtale. Hver vector embedding for semantisk s√∏gning.

Dette projekt handler ikke om at v√¶lge "den bedste database". Det handler om at forst√• **hvorn√•r** hver teknologi giver v√¶rdi, og hvad det koster at v√¶lge forkert.

For at kunne tr√¶ffe et fagligt begrundet databasevalg, identificerede jeg fire funktionelle krav som alle tre chatbot-typer afh√¶nger af.

---

## Fire kritiske krav

Moderne chatbot-arkitektur stiller fire ikke-negocierbare krav:

### 1. JSON-lagring med hurtig s√∏gning

Chatbeskeder er ikke rene SQL-r√¶kker. De indeholder metadata (timestamps, token counts), nested content og varierende strukturer. JSON er det naturlige format, men ikke alle databaser h√•ndterer JSON lige godt.

**Konkret krav:** Hent 50 samtaler med 500 beskeder p√• under 100ms.

<details>
<summary><strong>üìä Hvorfor JSON performance matters</strong></summary>

N√•r en authenticated user √•bner deres chathistorik, skal systemet:
- Hente 50 seneste samtaler
- Loade alle beskeder per samtale
- Parse JSON-indhold
- Render i UI

Ved 26√ó d√•rligere performance (MongoDB vs PostgreSQL) betyder det:
- PostgreSQL: 50ms ‚Üí flydende UX
- MongoDB: 1.3 sekunder ‚Üí frustrerende ventetid

For Guest Chatbot med session-baseret loading bliver denne forskel kritisk.
</details>

---

### 2. Vector embeddings for semantisk s√∏gning

Keyword search finder kun eksakte match. Men n√•r en bruger sp√∏rger *"Hvordan lindrer jeg hovedpine?"*, skal systemet finde samtaler om "migr√¶ne", "smertelindring" og "Panodil" ‚Äì selvom ordene er forskellige.

**L√∏sning:** Vector embeddings (1536-dimensionelle arrays fra OpenAI) gemmes i databasen og s√∏ges via cosine similarity.

<details>
<summary><strong>üîç Semantic search eksempel</strong></summary>

**User query:** "Hvordan lindrer jeg hovedpine?"

**System konverterer til embedding:**
```
[0.023, -0.891, 0.445, ... 1536 dimensions]
```

**Database finder lignende embeddings fra tidligere samtaler:**
- "Jeg har migr√¶ne, hvad hj√¶lper?" (similarity: 0.89)
- "Panodil vs Ipren til smertelindring" (similarity: 0.85)
- "Sp√¶ndingshovedpine √∏velser" (similarity: 0.82)

Uden vector search ville kun eksakte matches p√• "hovedpine" findes.
</details>

---

### 3. Mange samtidige brugere uden performance-tab

Realtidschat tolererer ikke slow queries. Ved 100+ samtidige connections skal systemet:
- H√•ndtere 1000+ writes/sekund (messages)
- Levere sub-100ms read latency
- Sikre consistency (ingen tabte beskeder)

---

### 4. Problemfri Blazor integration

Entity Framework Core er .NET's standard ORM. Men ikke alle database providers underst√∏tter samme features. Manglende `Include()` support betyder N+1 queries. Ingen transaction support betyder custom workarounds.

**Krav:** 100% EF Core feature support for standard LINQ patterns.

<details>
<summary><strong>üíª Hvad betyder manglende EF Core support?</strong></summary>

**PostgreSQL (standard pattern):**
```csharp
var conversations = await _context.Conversations
    .Where(c => c.UserId == userId)
    .Include(c => c.Messages)  // ‚úÖ Virker direkte
    .ToListAsync();
```

**MongoDB (workaround n√∏dvendig):**
```csharp
var conversations = await _context.Conversations
    .Where(c => c.UserId == userId)
    .ToListAsync();

// ‚ùå Include() virker ikke - manuel loop
foreach (var conv in conversations) {
    conv.Messages = await _context.Messages
        .Where(m => m.ConversationId == conv.Id)
        .ToListAsync();  // N+1 query problem
}
```

Resultat: 2√ó mere kode, 11 database roundtrips i stedet for 1.
</details>

---

## Hvad sker der hvis vi v√¶lger forkert?

Tre konkrete failure-scenarier illustrerer konsekvenserne:

### ‚ùå Scenarie 1: Database uden effektiv JSON-support

**Problem:** Manglende native JSON-h√•ndtering tvinger os til omfattende normalisering med komplekse joins.

**Konsekvens:** 
- Authenticated Chatbot: 2-3 sekunders load-tid i stedet for 50ms
- Developer friction: 3√ó mere kode for samme funktionalitet
- Skalerbarhed: Performance degraderer eksponentielt ved v√¶kst

<details>
<summary><strong>üìâ Performance breakdown</strong></summary>

**Normalized structure (uden JSON):**
```
Messages ‚Üí 500 rows
MessageMetadata ‚Üí 500 rows
MessageTokens ‚Üí 500 rows
= 3 tables √ó 500 rows = 1500 rows med JOINs
```

**JSONB structure:**
```
Messages ‚Üí 500 rows med embedded JSON
= 1 table √ó 500 rows, ingen JOINs
```

Query complexity: O(n¬≥) vs O(n) - massiv forskel ved scale.
</details>

---

### ‚ùå Scenarie 2: Ingen native vector search

**Problem:** Separat vector database (Pinecone/Weaviate) kr√¶ver:
- Data duplication (beskeder b√•de i main DB og vector DB)
- Synkronisering mellem systemer
- Dobbelt hosting cost
- Kompleks failure handling

**Konsekvens:**
- Semantic search queries kr√¶ver 2+ database roundtrips
- Data consistency issues (sync lag)
- √Örlig ekstra cost: ~$2,400 for 10k users

<details>
<summary><strong>üîó Separate database complexity</strong></summary>

**Query flow med separat vector DB:**
1. App ‚Üí Vector DB: "Find similar conversations" (200ms)
2. Vector DB ‚Üí App: Returns IDs [conv1, conv2, conv3]
3. App ‚Üí Main DB: "Get conversations by IDs" (150ms)
4. App: Client-side merging + filtering (50ms)

**Total: 400ms + complexity**

**Med native vector (pgvector):**
1. App ‚Üí PostgreSQL: Combined query (89ms)

**Total: 89ms, zero sync issues**
</details>

---

### ‚ùå Scenarie 3: Manglende ACID-garantier

**Problem:** NoSQL eventual consistency kan resultere i partial saves ved crashes.

**Konsekvens:**
- Guest Chatbot: Bruger ser egen besked, men intet bot-svar
- Authenticated Chatbot: "Saved successfully" betyder ikke persistent data
- Owner Chatbot: Analytics dashboards viser inkonsistent data
- GDPR-risiko: Kan ikke garantere data-deletion

<details>
<summary><strong>‚ö†Ô∏è Konkret crash-scenarie</strong></summary>

**System crasher mellem user message og bot response:**

**PostgreSQL (ACID):**
- Transaction rollback automatisk
- Database returnerer til clean state
- User ser: Ingen samtale (forventet opf√∏rsel)

**MongoDB (BASE):**
- User message persisteret
- Bot response tabt
- User ser: Halv samtale (broken UX)

Test-resultat: MongoDB 70% partial saves ved 10 simulated crashes.
</details>

---

## Beslutningsmatrix

For at evaluere databaser systematisk definerede jeg v√¶gtede kriterier baseret p√• projektets krav:

| Kriterium | V√¶gt | Hvorfor det matters |
|-----------|------|---------------------|
| **AI/ML Kompatibilitet** | 30% | Vector search + JSON er kernefunktionalitet |
| **Performance** | 25% | Realtidschat tolererer ikke slow queries |
| **Blazor Integration** | 20% | EF Core support = udviklingshastighed |
| **Skalerbarbarhed** | 15% | Prototype ‚Üí produktion uden rewrite |
| **Omkostninger** | 10% | Drift + udvikling skal v√¶re b√¶redygtigt |

<details>
<summary><strong>üéØ Hvorfor denne v√¶gtning?</strong></summary>

**AI/ML top priority (30%):**
Manglende vector support eliminerer semantic search helt. D√•rlig JSON performance g√∏r Authenticated Chatbot ubrugeligt. Dette er go/no-go kriterier.

**Performance #2 (25%):**
Chatbot UX lever eller d√∏r p√• response time. 50ms vs 2 sekunder er forskellen mellem "flydende" og "frustrerende".

**Integration matters (20%):**
Et semester-projekt har begr√¶nset tid. EF Core workarounds spiser udviklingsdage og introducerer bugs.

**Skalerbarhed + Cost lavere (15% + 10%):**
Vigtigt, men kan h√•ndteres senere. Prototype kan k√∏re p√• billig tier. Production scaling er fremtidig concern.
</details>

---

## Min tilgang

I stedet for at v√¶lge baseret p√• "hvad folk anbefaler", besluttede jeg at kombinere:

1. **Systematisk research** ‚Üí Peer-reviewed studier + production cases
2. **Praktisk test** ‚Üí Benchmarks p√• realistic data
3. **Arkitektur-design** ‚Üí Konkret implementation

M√•let var ikke at finde "den bedste database", men at forst√• **trade-offs** og kunne forsvare valget med evidens.

---

## N√¶ste skridt: Indsamle evidens

Nu skulle jeg finde p√•lidelige kilder der kunne besvare mine fire forskningssp√∏rgsm√•l. Men hvilke kilder var trov√¶rdige? Og hvordan undgik jeg confirmation bias?

*Hvordan unders√∏gte jeg disse krav systematisk? Hvilke overraskende resultater fandt jeg?*

**N√¶ste:** [Research ‚Üí]({{< relref "database/research.md" >}})